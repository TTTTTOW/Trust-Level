which(is.na(testdata))
my_forest = randomForest(fraud ~ trustLevel + totalScanTimeInSeconds + grandTotal + lineItemVoids + scansWithoutRegistration + quantityModifications + quantityModifications + scannedLineItemsPerSecond + valuePerSecond + lineItemVoidsPerPosition, data = traindata, ntree=500,
importance=TRUE)
gc()
importance(my_forest)
varImpPlot(my_forest)
forest_prediction <- predict(my_forest, testdata)
#Saving in a dataframe
final_solution <- data.frame(transactionID = testdata$transactionID, fraud = forest_prediction )
Write_csv(final_solution, “RF_solution.csv”)
#Saving in a csv file
Write_csv(final_solution, "RF_solution.csv")
#Saving in a csv file
write_csv(final_solution, "RF_solution.csv")
#Saving in a csv file
write.csv(final_solution, "RF_solution.csv")
install.packages("neuralnet")
library(neuralnet)
f<-as.formula(paste("fraud ~",paste(n[!n %in% "fraud"],collapse = "+")))
model<-neuralnet(f,data = traindata,hidden = c(5,3),linear.output = T)
plot(model)
library(nnet)
formula <- fraud ~ .;
traindata.nnet = nnet(
formula = formula,
data = traindata,
size = 3,
decay = 0.1,
linout = T,
trace = F
)
traindata.nnet = nnet(
formula = formula,
data = traindata,
size = 3,
decay = 0.01,
linout = T,
trace = F
entropy = TRUE
)
traindata.nnet = nnet(
formula = formula,
data = traindata,
size = 3,
decay = 0.01,
linout = T,
trace = F,
entropy = TRUE
)
library(nnet)
nn.output <- matrix(0,nrow(traindata),2)
nn.output[which(traindata[,10]==1),1] <- 1
nn.output[which(traindata[,10]==1),2] <- 0
nn.output[which(traindata[,10]==2),1] <- 0
nn.output[which(traindata[,10]==2),2] <- 2
# 或者 nn.output = class.ind(data.train[,10])
model <- nnet(traindata[,-10],
nn.output,
size = 4, softmax=TRUE, maxit=200, )
summary(model)
View(nn.output)
cvsamp <- function(k, datasize){
cvlist <- list()
subsetSize <- datasize/k
datarow <- 1:datasize
for (i in 1:k-2) {
group <- sample(datarow, subsetSize)
cvlist <- append(cvlist, list(group))
datarow <- setdiff(datarow, group)
}
cvlist <- append(cvlist, list(datarow))
cvlist <- cvlist[-length(cvlist)]
}
k <- 10
cvlist <- cvsamp(k = k,datasize = nrow(traindata))
cvlist
error <- function(k,hp){
err <- 0
for (i in 1:k){
cvlist <- cvsamp(k = k,datasize = nrow(data.train))
trainset <- data.train[-unlist(cvlist[i]),]
testset <- data.train[unlist(cvlist[i]),]
Y=class.ind(trainset[,10])
ytrue <- testset$Class
model <- nnet(trainset[,-10],Y,softmax=TRUE,
size=hp[1],maxit=hp[2])
Ypred <- predict(model,testset[,-10])
ypred <- max.col(Ypred)
err <- err + sum(ypred != ytrue)/nrow(testset)
}
return(err/k)
size <- 1:10
errlist <- vector()
for (i in size){
errlist <- c(errlist, error(k,c(i,200)))
}
plot(size, errlist)
error <- function(k,hp){
err <- 0
for (i in 1:k){
cvlist <- cvsamp(k = k,datasize = nrow(data.train))
trainset <- data.train[-unlist(cvlist[i]),]
testset <- data.train[unlist(cvlist[i]),]
Y=class.ind(trainset[,10])
ytrue <- testset$Class
model <- nnet(trainset[,-10],Y,softmax=TRUE,
size=hp[1],maxit=hp[2])
Ypred <- predict(model,testset[,-10])
ypred <- max.col(Ypred)
err <- err + sum(ypred != ytrue)/nrow(testset)
}
return(err/k)
}
error <- function(k,hp){
err <- 0
for (i in 1:k){
cvlist <- cvsamp(k = k,datasize = nrow(traindata))
trainset <- traindata[-unlist(cvlist[i]),]
testset <- traindata[unlist(cvlist[i]),]
Y=class.ind(trainset[,10])
ytrue <- testset$fraud
model <- nnet(trainset[,-10],Y,softmax=TRUE,
size=hp[1],maxit=hp[2])
Ypred <- predict(model,testset[,-10])
ypred <- max.col(Ypred)
err <- err + sum(ypred != ytrue)/nrow(testset)
}
return(err/k)
}
end
end()
k <- 10
cvlist <- cvsamp(k = k,datasize = nrow(traindata))
cvlist
#Importing the data
traindata<-read.csv("D:/R-Data Analysis/Final Project/data/mgis489_train.csv")
testdata<-read.csv("D:/R-Data Analysis/Final Project/data//mgis489_test.csv")
dim(testdata)
#Checking the structure and dimension of traindata
str(traindata)
dim(traindata)
#Doing necessary changes to dimensions of traindata
traindata$fraud<-as.factor(traindata$fraud)
#str(traindata)
#Checking the position of missing value
which(is.na(traindata))
#Rough Imputation Of Missing Values
library(randomForest)
traindata<-na.roughfix(traindata)
which(is.na(traindata))
#Checking the structure and dimension of testdata
dim(testdata)
str(testdata)
#Checking the position of missing value
which(is.na(testdata))
#Rough Imputation Of Missing Values
testdata<-na.roughfix(testdata)
which(is.na(testdata))
library(nnet)
nn.output <- matrix(0,nrow(traindata),2)
nn.output[which(traindata[,10]==1),1] <- 1
nn.output[which(traindata[,10]==1),2] <- 0
nn.output[which(traindata[,10]==2),1] <- 0
nn.output[which(traindata[,10]==2),2] <- 2
# 或者 nn.output = class.ind(data.train[,10])
model <- nnet(traindata[,-10],
nn.output,
size = 4, softmax=TRUE, maxit=200, )
summary(model)
# 将数据集划分为大小相近的k个子集
# 将数据集划分为大小相近的k个子集
cvsamp <- function(k, datasize){
cvlist <- list()
subsetSize <- datasize/k
datarow <- 1:datasize
for (i in 1:k-2) {
group <- sample(datarow, subsetSize)
cvlist <- append(cvlist, list(group))
datarow <- setdiff(datarow, group)
}
cvlist <- append(cvlist, list(datarow))
cvlist <- cvlist[-length(cvlist)]
}
k <- 10
cvlist <- cvsamp(k = k,datasize = nrow(traindata))
cvlist
# 计算k次训练得到的模型的测试误差大小
error <- function(k,hp){
err <- 0
for (i in 1:k){
cvlist <- cvsamp(k = k,datasize = nrow(traindata))
trainset <- traindata[-unlist(cvlist[i]),]
testset <- traindata[unlist(cvlist[i]),]
Y=class.ind(trainset[,10])
ytrue <- testset$fraud
model <- nnet(trainset[,-10],Y,softmax=TRUE,
size=hp[1],maxit=hp[2])
Ypred <- predict(model,testset[,-10])
ypred <- max.col(Ypred)
err <- err + sum(ypred != ytrue)/nrow(testset)
}
return(err/k)
}
size <- 1:10
errlist <- vector()
for (i in size){
errlist <- c(errlist, error(k,c(i,200)))
}
plot(size, errlist)
maxit <- seq(1,500,10)
errlist <- vector()
for (i in maxit){
errlist <- c(errlist, error(k,c(4,i)))
}
plot(maxit[2:length(maxit)], errlist[2:length(errlist)],
type = "b")
View(model)
View(model)
View(model)
View(model)
View(model)
View(model)
View(model)
View(model)
View(nn.output)
View(nn.output)
View(nn.output)
View(nn.output)
View(nn.output)
View(nn.output)
fraud.predict = predict(model,testdata,type = "fraud")
nn.table = table(testdata$transactionID,fraud.predict)
nn.table
#predict
fraud.predict = predict(model,testdata,type = "class")
#predict
fraud.predict = predict.nnet(model,testdata,type = "class")
#predict
fraud.predict = predict(model,testdata,type = "class")
#### EDA ####
#Importing the data
traindata<-read.csv("D:/R-Data Analysis/Final Project/data/mgis489_train.csv")
testdata<-read.csv("D:/R-Data Analysis/Final Project/data//mgis489_test.csv")
dim(testdata)
#Checking the structure and dimension of traindata
str(traindata)
dim(traindata)
#Doing necessary changes to dimensions of traindata
traindata$fraud<-as.factor(traindata$fraud)
#str(traindata)
#Checking the position of missing value
which(is.na(traindata))
#Rough Imputation Of Missing Values
library(randomForest)
traindata<-na.roughfix(traindata)
which(is.na(traindata))
#Checking the structure and dimension of testdata
dim(testdata)
str(testdata)
#Checking the position of missing value
which(is.na(testdata))
#Rough Imputation Of Missing Values
testdata<-na.roughfix(testdata)
which(is.na(testdata))
featurePlot(x = traindata[, 1:10],
y = traindata$fraud,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
library(tidyverse)
featurePlot(x = traindata[, 1:10],
y = traindata$fraud,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
library(caret)
install.packages(caret)
help("featurePlot")
install.packages(caret)
install.packages("caret")
install.packages("caret")
featurePlot(x = traindata[, 1:10],
y = traindata$fraud,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
library(caret)
featurePlot(x = traindata[, 1:10],
y = traindata$fraud,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
fraud <- as.numeric(traindata$fraud)
featurePlot(x = traindata[, 1:10],
y = fraud,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
#### EDA ####
#Importing the data
traindata<-read.csv("D:/R-Data Analysis/Final Project/data/mgis489_train.csv")
testdata<-read.csv("D:/R-Data Analysis/Final Project/data//mgis489_test.csv")
dim(testdata)
#Checking the structure and dimension of traindata
str(traindata)
dim(traindata)
#Doing necessary changes to dimensions of traindata
traindata$fraud<-as.factor(traindata$fraud)
#str(traindata)
#Checking the position of missing value
which(is.na(traindata))
#Rough Imputation Of Missing Values
library(randomForest)
traindata<-na.roughfix(traindata)
which(is.na(traindata))
#Checking the structure and dimension of testdata
dim(testdata)
str(testdata)
#Checking the position of missing value
which(is.na(testdata))
#Rough Imputation Of Missing Values
testdata<-na.roughfix(testdata)
which(is.na(testdata))
library(tidyverse)
library(caret)
fraud <- as.numeric(traindata$fraud)
traindata2 <- na.omit(traindata)
featurePlot(x = traindata2[, 1:10],
y = traindata2$fraud,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
fraud <- as.integer(traindata$fraud)
featurePlot(x = traindata2[, 1:10],
y = fraud,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
fraud <- as.character(traindata$fraud)
featurePlot(x = traindata2[, 1:10],
y = fraud,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
#### EDA ####
#Importing the data
traindata<-read.csv("D:/R-Data Analysis/Final Project/data/mgis489_train.csv")
testdata<-read.csv("D:/R-Data Analysis/Final Project/data//mgis489_test.csv")
dim(testdata)
#Checking the structure and dimension of traindata
str(traindata)
dim(traindata)
#Doing necessary changes to dimensions of traindata
traindata$fraud<-as.factor(traindata$fraud)
#str(traindata)
#Checking the position of missing value
which(is.na(traindata))
#Rough Imputation Of Missing Values
library(randomForest)
traindata<-na.roughfix(traindata)
which(is.na(traindata))
#Checking the structure and dimension of testdata
dim(testdata)
str(testdata)
#Checking the position of missing value
which(is.na(testdata))
#Rough Imputation Of Missing Values
testdata<-na.roughfix(testdata)
which(is.na(testdata))
## training set
traindata$trustLevel <- as.factor(traindata$trustLevel)
TotalItem <- traindata$totalScanTimeInSeconds * traindata$scannedLineItemsPerSecond
Train <- data.frame(traindata, TotalItem = TotalItem)
Train <- Train[,-c(3,6,7,9)]
## testing set
testdata$trustLevel <- as.factor(testdata$trustLevel)
TotalItem <- testdata$totalScanTimeInSeconds * testdata$scannedLineItemsPerSecond
Test <- data.frame(testdata, TotalItem = TotalItem)
Test <- Test[,-c(3,6,7,9)]
## true value
formula1 <- "fraud~trustLevel + TotalItem + lineItemVoids + scansWithoutRegistration +
totalScanTimeInSeconds "
formula2 <- "fraud~trustLevel + TotalItem + lineItemVoids + scansWithoutRegistration +
totalScanTimeInSeconds + I( totalScanTimeInSeconds * valuePerSecond ) +
I( totalScanTimeInSeconds * valuePerSecond^2 )"
formula3 <- "fraud~trustLevel + TotalItem + lineItemVoids + scansWithoutRegistration +
totalScanTimeInSeconds + I( totalScanTimeInSeconds * valuePerSecond ) +
I( totalScanTimeInSeconds * valuePerSecond^(3.5) )"
fit1 <- glm(formula=formula1,data=Train,family=binomial(link=logit))
fit2 <- glm(formula=formula2,data=Train,family=binomial(link=logit))
fit3 <- glm(formula=formula3,data=Train,family=binomial(link=logit))
py1 <- predict(fit1,newdata=Test, type = "response")
py2 <- predict(fit2,newdata=Test, type = "response")
py3 <- predict(fit3,newdata=Test, type = "response")
py1 <- predict(fit1,data=Test, type = "response")
write.csv(py1, "py1_solution.csv")
py1 <- predict(fit1,Test)
View(testdata)
Test <- data.frame(testdata, TotalItem = TotalItem)
py1 <- predict(fit1,Test)
py1
P1 <- predict(fit1, Test, type ="response")
P2 <- predict(fit2, Test, type ="response")
P3 <- predict(fit3, Test, type ="response")
P_M1 <- 0.4*P1 + 0.6*P2
P_M2 <- 0.4*P1 + 0.6*P3
P_M3 <- 0.3*P1 + 0.1*P2 + 0.6*P3
Pred1 <- ifelse(P_M1>5/7,1,0)
Pred2 <- ifelse(P_M2>5/7,1,0)
Pred3 <- ifelse(P_M3>5/7,1,0)
Pred_df <- data.frame(Pred1,Pred2,Pred3)
# Majority Vote
Pred_df$vote <- apply(Pred_df, 1, function(p){
re <- ifelse(sum(p) > 1,1,0)
})
submit <- as.data.frame(Pred_df$vote)
colnames(submit) <- 'fraud'
write.csv(submit, file='final.csv')
AveValue <- Train0$grandTotal / TotalItem
AveValue <- Train$grandTotal / TotalItem
library(ggplot2)
Train0 <- read.csv(file = "D:/R-Data Analysis/Final Project/data/train.csv", sep = "|")
Train0$trustLevel <- as.factor(Train0$trustLevel)
TotalItem <- Train0$totalScanTimeInSeconds * Train0$scannedLineItemsPerSecond
AveValue <- Train0$grandTotal / TotalItem
Train1 <- data.frame(Train0, TotalItem = TotalItem)
############################## logistic regression ##################################
cv_design <- function(n, fold = 10){
m <- floor(n/fold)
r <- n%%fold
p1 <- rep(m, fold)
p2 <- rep(0, fold)
if (r>=1){
p2[1:r] <- 1
}
p <- p1 + p2
ub <- cumsum(p)
lb <- ub - p + 1
x <- sample(n)
IND <- vector("list",fold)
for (i in 1:fold){
IND[[i]] <- x[(lb[i]):(ub[i])]
}
return(IND)
}
cv_logistic_probs <- function(D,formula, fold = 10){
n <- length(D[,1])
IND <- cv_design(n, fold)
probs <- rep(0,n)
options(warn=-1)
for (i in 1:fold){
test_ind <- IND[[i]]
Train <- D[-test_ind,]
Test <- D[test_ind,]
fit <- glm(formula=formula,data=Train,family=binomial(link=logit))
py <- predict(fit,newdata=data.frame(Test), type = "response")
probs[test_ind] <- py
}
return(probs)
}
################################## Loss results #################################
######## all 0 ##########
pred0 <- rep(0, length(Train1[,1]))
sum(pred0!=Train1$fraud)
## 104
#########################
######################################  Train1 ###################################
formula1 <- "fraud~."
loss1 <- rep(0, 100)
loss2 <- rep(0, 100)
for (i in 1:100){
pred1 <- pred0
probs <- cv_logistic_probs(Train1, formula1, 10)
pred1[ which(  probs > 5/7  ) ] <- 1
loss1[i] <- lossDMC(true = Train1$fraud,
pred = pred1)
loss2[i] <- sum(pred1!=Train1$fraud)
}
mean(loss1)
## -251.85
mean(loss2)
## 16.42
#######################################################################################
#################################  Train0 ###################################
formula1 <- "fraud~."
loss1 <- rep(0, 100)
loss2 <- rep(0, 100)
for (i in 1:100){
pred1 <- pred0
probs <- cv_logistic_probs(Train0, formula1, 10)
pred1[ which(  probs > 5/7  ) ] <- 1
loss1[i] <- lossDMC(true = Train0$fraud,
pred = pred1)
loss2[i] <- sum(pred1!=Train0$fraud)
}
mean(loss1)
## -87.8
mean(loss2)
## 32.9
###############################################################################################
fit_final <- glm(fraud~., data=Train1, family=binomial(link=logit))
summary(fit_final)
pred_final <- pred0
pred_final[which(fit_final$fitted.values>5/7)] <- 1
